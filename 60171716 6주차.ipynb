{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >=(3, 5)\n",
    "from tensorflow import keras\n",
    "\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 가로 * 세로 = row * clomun\n",
    "\n",
    "# Each number size = 8 by 8\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "x_data = digits.data\n",
    "y_data = digits.target\n",
    "\n",
    "# Split train and test data by 7:3\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.3)\n",
    "\n",
    "# Set class names\n",
    "class_names = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Sample images from 1st to 10th\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"ann\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok = True)\n",
    "def save_fig(fig_id, tight_layout = True, fig_extension = \"png\", resolution = 300) :\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"그림 저장 : \", fig_id)\n",
    "    if tight_layout :\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format = fig_extension, dpi = resolution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "그림 저장 :  digits_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x86.4 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Should resize x_train's shape to get result we want\n",
    "n_rows = 1\n",
    "n_cols = 10\n",
    "plt.figure(figsize = (n_cols * 1.2, n_rows * 1.2))\n",
    "for row in range(n_rows) :\n",
    "    for col in range(n_cols) :\n",
    "        idx = n_cols * row + col\n",
    "        plt.subplot(n_rows,n_cols, idx + 1)\n",
    "        plt.imshow(x_train[idx].reshape(8, 8), cmap = \"binary\", interpolation = \"nearest\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(class_names[y_train[idx]], fontsize = 12)\n",
    "plt.subplots_adjust(wspace = 0.2, hspace = 0.5)\n",
    "save_fig(\"digits_plot\", tight_layout = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_19 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 300)               19500     \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 50,610\n",
      "Trainable params: 50,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set model and add layers\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [8, 8]))\n",
    "# relu : usually used in Hidden layers \n",
    "model.add(keras.layers.Dense(300, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation = \"relu\"))\n",
    "# softmax : usually used in Output layer\n",
    "model.add(keras.layers.Dense(10, activation = \"softmax\"))\n",
    "\n",
    "# Show current layer status\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"sgd\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 8, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8), dtype=tf.float32, name='flatten_19_input'), name='flatten_19_input', description=\"created by layer 'flatten_19_input'\"), but it was called on an input with incompatible shape (None, 64).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 8, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8), dtype=tf.float32, name='flatten_19_input'), name='flatten_19_input', description=\"created by layer 'flatten_19_input'\"), but it was called on an input with incompatible shape (None, 64).\n",
      " 3/40 [=>............................] - ETA: 1s - loss: 9.3224 - accuracy: 0.1042 WARNING:tensorflow:Model was constructed with shape (None, 8, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8), dtype=tf.float32, name='flatten_19_input'), name='flatten_19_input', description=\"created by layer 'flatten_19_input'\"), but it was called on an input with incompatible shape (None, 64).\n",
      "40/40 [==============================] - 1s 8ms/step - loss: 1.5439 - accuracy: 0.6786 - val_loss: 0.4574 - val_accuracy: 0.8852\n",
      "Epoch 2/30\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2795 - accuracy: 0.9228 - val_loss: 0.3084 - val_accuracy: 0.9148\n",
      "Epoch 3/30\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1842 - accuracy: 0.9531 - val_loss: 0.2843 - val_accuracy: 0.9130\n",
      "Epoch 4/30\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1436 - accuracy: 0.9634 - val_loss: 0.1767 - val_accuracy: 0.9556\n",
      "Epoch 5/30\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1059 - accuracy: 0.9737 - val_loss: 0.1799 - val_accuracy: 0.9481\n",
      "Epoch 6/30\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0857 - accuracy: 0.9841 - val_loss: 0.1645 - val_accuracy: 0.9537\n",
      "Epoch 7/30\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0740 - accuracy: 0.9905 - val_loss: 0.2409 - val_accuracy: 0.9074\n",
      "Epoch 8/30\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.9849 - val_loss: 0.1383 - val_accuracy: 0.9574\n",
      "Epoch 9/30\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0573 - accuracy: 0.9912 - val_loss: 0.1379 - val_accuracy: 0.9648\n",
      "Epoch 10/30\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 0.9944 - val_loss: 0.1340 - val_accuracy: 0.9611\n",
      "Epoch 11/30\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0451 - accuracy: 0.9952 - val_loss: 0.1325 - val_accuracy: 0.9648\n",
      "Epoch 12/30\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0393 - accuracy: 0.9936 - val_loss: 0.1246 - val_accuracy: 0.9593\n",
      "Epoch 13/30\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0339 - accuracy: 0.9968 - val_loss: 0.1463 - val_accuracy: 0.9574\n",
      "Epoch 14/30\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0318 - accuracy: 0.9960 - val_loss: 0.1249 - val_accuracy: 0.9685\n",
      "Epoch 15/30\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0278 - accuracy: 0.9976 - val_loss: 0.1335 - val_accuracy: 0.9648\n",
      "Epoch 16/30\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0263 - accuracy: 0.9984 - val_loss: 0.1167 - val_accuracy: 0.9648\n",
      "Epoch 17/30\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0242 - accuracy: 0.9984 - val_loss: 0.1218 - val_accuracy: 0.9630\n",
      "Epoch 18/30\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0224 - accuracy: 0.9992 - val_loss: 0.1166 - val_accuracy: 0.9685\n",
      "Epoch 19/30\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0220 - accuracy: 0.9984 - val_loss: 0.1484 - val_accuracy: 0.9426\n",
      "Epoch 20/30\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.1102 - val_accuracy: 0.9685\n",
      "Epoch 21/30\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.1307 - val_accuracy: 0.9574\n",
      "Epoch 22/30\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0181 - accuracy: 0.9984 - val_loss: 0.1120 - val_accuracy: 0.9685\n",
      "Epoch 23/30\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0163 - accuracy: 0.9992 - val_loss: 0.1227 - val_accuracy: 0.9667\n",
      "Epoch 24/30\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.1075 - val_accuracy: 0.9648\n",
      "Epoch 25/30\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.1111 - val_accuracy: 0.9648\n",
      "Epoch 26/30\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.1095 - val_accuracy: 0.9685\n",
      "Epoch 27/30\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0128 - accuracy: 0.9992 - val_loss: 0.1053 - val_accuracy: 0.9630\n",
      "Epoch 28/30\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.1048 - val_accuracy: 0.9630\n",
      "Epoch 29/30\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.1073 - val_accuracy: 0.9648\n",
      "Epoch 30/30\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.1061 - val_accuracy: 0.9704\n",
      "time :  3.8553409576416016\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "import time\n",
    "tb_hist = keras.callbacks.TensorBoard(log_dir = './graph', histogram_freq = 0, write_graph = True, write_images = True)\n",
    "start = time.time()\n",
    "history = model.fit(x_train, y_train, epochs = 30, validation_data = (x_test, y_test), callbacks = [tb_hist])\n",
    "print(\"time : \", time.time()-start) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b2a764109c02714c2c157764b6d2289713d3b099c0d172e9b98f933403ab0fd4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
